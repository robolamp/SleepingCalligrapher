{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2DTranspose, Conv2D\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_image(pixels):\n",
    "    npix = int(np.sqrt(pixels.shape[0]))\n",
    "    return np.reshape(pixels, (npix, npix))\n",
    "\n",
    "def draw_image(image):\n",
    "    image = np.reshape(image, (image.shape[0], image.shape[1]))\n",
    "    plt.imshow(image, cmap = plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_image(reshape_image(mnist.train.images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images.reshape(-1,  \n",
    "                                     28, \n",
    "                                     28, \n",
    "                                     1).astype(np.float32)\n",
    "y_train = mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c21e6d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_image(X_train[10]), y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN example\n",
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dropout = 0.4\n",
    "gen_input_dim = 7\n",
    "gen_depth = 128\n",
    "gen_noise_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              319872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6272)              25088     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 16)        12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         401       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 614,721\n",
      "Trainable params: 601,953\n",
      "Non-trainable params: 12,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gennet = Sequential()\n",
    "\n",
    "# Input \n",
    "# fully-connected layer\n",
    "gennet.add(Dense(gen_input_dim * gen_input_dim * gen_depth, \n",
    "                 input_dim=gen_noise_dim))\n",
    "gennet.add(BatchNormalization(momentum=0.9))\n",
    "gennet.add(Activation('relu'))\n",
    "gennet.add(Reshape((gen_input_dim, gen_input_dim, gen_depth)))\n",
    "gennet.add(Dropout(gen_dropout))\n",
    "\n",
    "# Deconvolution layers\n",
    "gennet.add(UpSampling2D())\n",
    "gennet.add(Conv2DTranspose(int(gen_depth / 2), 5, padding='same'))\n",
    "gennet.add(BatchNormalization(momentum=0.9))\n",
    "gennet.add(Activation('relu'))\n",
    "\n",
    "gennet.add(UpSampling2D())\n",
    "gennet.add(Conv2DTranspose(int(gen_depth / 4), 5, padding='same'))\n",
    "gennet.add(BatchNormalization(momentum=0.9))\n",
    "gennet.add(Activation('relu'))\n",
    "\n",
    "gennet.add(Conv2DTranspose(int(gen_depth / 8), 5, padding='same'))\n",
    "gennet.add(BatchNormalization(momentum=0.9))\n",
    "gennet.add(Activation('relu'))\n",
    "\n",
    "# Output\n",
    "gennet.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "gennet.add(Activation('sigmoid'))\n",
    "\n",
    "gennet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_depth = 64\n",
    "disc_dropout = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,305,409\n",
      "Trainable params: 4,305,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discnet = Sequential()\n",
    "\n",
    "# Input\n",
    "discnet.add(Conv2D(disc_depth, 5, strides=2, input_shape=(28, 28, 1), \n",
    "                   padding='same'))\n",
    "discnet.add(Activation('relu'))\n",
    "discnet.add(Dropout(disc_dropout))\n",
    "\n",
    "discnet.add(Conv2D(disc_depth*2, 5, strides=2, padding='same'))\n",
    "discnet.add(Activation('relu'))\n",
    "discnet.add(Dropout(disc_dropout))\n",
    "\n",
    "discnet.add(Conv2D(disc_depth*4, 5, strides=2, padding='same'))\n",
    "discnet.add(Activation('relu'))\n",
    "discnet.add(Dropout(disc_dropout))\n",
    "\n",
    "discnet.add(Conv2D(disc_depth*8, 5, strides=2, padding='same'))\n",
    "discnet.add(Activation('relu'))\n",
    "discnet.add(Dropout(disc_dropout))\n",
    "\n",
    "# Out: scalar estimation of probability\n",
    "discnet.add(Flatten())\n",
    "discnet.add(Dense(1))\n",
    "discnet.add(Activation('sigmoid'))\n",
    "\n",
    "discnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "discmodel = Sequential()\n",
    "discmodel.add(discnet)\n",
    "discmodel.compile(loss='binary_crossentropy', \n",
    "                  optimizer=RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "advmodel = Sequential()\n",
    "advmodel.add(gennet)\n",
    "advmodel.add(discnet)\n",
    "advmodel.compile(loss='binary_crossentropy', \n",
    "                 optimizer=RMSprop(lr=0.00084, clipvalue=1.0, decay=3e-8),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on 0th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [0.00055754272, 1.0]\n",
      "Trained on 1th bath of 100 | Disc loss: [1.946584, 0.5] | Adv loss [0.50750268, 1.0]\n",
      "Trained on 2th bath of 100 | Disc loss: [0.9880417, 0.5] | Adv loss [0.18030024, 1.0]\n",
      "Trained on 3th bath of 100 | Disc loss: [2.5294306, 0.5] | Adv loss [0.17266101, 1.0]\n",
      "Trained on 4th bath of 100 | Disc loss: [1.7647054, 0.5] | Adv loss [0.073968023, 1.0]\n",
      "Trained on 5th bath of 100 | Disc loss: [1.3071071, 0.5] | Adv loss [0.041431986, 1.0]\n",
      "Trained on 6th bath of 100 | Disc loss: [1.0555674, 0.5] | Adv loss [0.037950035, 1.0]\n",
      "Trained on 7th bath of 100 | Disc loss: [0.86635274, 0.5] | Adv loss [0.013742178, 1.0]\n",
      "Trained on 8th bath of 100 | Disc loss: [0.53876978, 0.5] | Adv loss [0.0052225417, 1.0]\n",
      "Trained on 9th bath of 100 | Disc loss: [0.39674208, 0.5] | Adv loss [0.0032346086, 1.0]\n",
      "Trained on 10th bath of 100 | Disc loss: [0.33873442, 0.97265625] | Adv loss [0.00019404983, 1.0]\n",
      "Trained on 11th bath of 100 | Disc loss: [0.31484738, 1.0] | Adv loss [0.00023230485, 1.0]\n",
      "Trained on 12th bath of 100 | Disc loss: [0.27485013, 1.0] | Adv loss [0.0011947958, 1.0]\n",
      "Trained on 13th bath of 100 | Disc loss: [0.19549291, 1.0] | Adv loss [0.52174127, 0.7578125]\n",
      "Trained on 14th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 15th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 16th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 17th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 18th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 19th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 20th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 21th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 22th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 23th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 24th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 25th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 26th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 27th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 28th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 29th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 30th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 31th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 32th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 33th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 34th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 35th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 36th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 37th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 38th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 39th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 40th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 41th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 42th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 43th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 44th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 45th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 46th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 47th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 48th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 49th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 50th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 51th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 52th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 53th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 54th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 55th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 56th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 57th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 58th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 59th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 60th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 61th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 62th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 63th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 64th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 65th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 66th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 67th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 68th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 69th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 70th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 71th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 72th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 73th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 74th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 75th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 76th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 77th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 78th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 79th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 80th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 81th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 82th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 83th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 84th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 85th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 86th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 87th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 88th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 89th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 90th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 91th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 92th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on 93th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 94th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 95th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 96th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 97th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 98th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n",
      "Trained on 99th bath of 100 | Disc loss: [7.9711924, 0.5] | Adv loss [1.1920933e-07, 1.0]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_iters = 100\n",
    "\n",
    "disc_losses = []\n",
    "adv_losses = []\n",
    "\n",
    "for i in range(train_iters):\n",
    "    # Get random real images\n",
    "    images_true = X_train[np.random.randint(0, \n",
    "                                            X_train.shape[0], \n",
    "                                            size=batch_size)]\n",
    "    # Generate images from noise\n",
    "    noise = np.random.uniform(-1.0, 1.0, \n",
    "                              size=[batch_size, gen_noise_dim])\n",
    "    images_fake = gennet.predict(noise)\n",
    "    # Compose training data for discriminator\n",
    "    x = np.concatenate((images_fake, images_true))\n",
    "    y = np.concatenate((np.zeros((batch_size, 1)), \n",
    "                        np.ones((batch_size, 1))))\n",
    "    # Train discriminator on composed data\n",
    "    dics_loss = discmodel.train_on_batch(x, y)\n",
    "    disc_losses.append(dics_loss) \n",
    "    \n",
    "    # Compose trainig data for adversarial net\n",
    "    noise = np.random.uniform(-1.0, 1.0, \n",
    "                              size=[batch_size, gen_noise_dim])\n",
    "    y = np.ones([batch_size, 1])\n",
    "    # Train adversarial net on composed data\n",
    "    adv_loss = advmodel.train_on_batch(noise, y)\n",
    "    adv_losses.append(adv_loss)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Trained on {}th bath of {} | Disc loss: {} | Adv loss {}\".format(i, train_iters, dics_loss, adv_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
